# core/llm.py
"""
Interface com LLM - Gen√©rica e configur√°vel
‚úÖ MELHORADO: Abordagem consultiva + descoberta ativa + mem√≥ria robusta
"""

import os
from typing import Dict, Any, List
from openai import OpenAI
import json
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()


class LLMClient:
    """Cliente gen√©rico para LLM"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = config.get("model", "gpt-4o-mini")
        self.temperature = config.get("temperature", 0.7)
        self.max_tokens = config.get("max_tokens", 500)
        
        # Inicializa cliente OpenAI com verifica√ß√£o da API key
        api_key = config.get("api_key") or os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError(
                "API Key da OpenAI n√£o encontrada! "
                "Configure OPENAI_API_KEY no arquivo .env ou na config do tenant."
            )
        
        try:
            self.client = OpenAI(api_key=api_key)
            self._test_connection()
        except Exception as e:
            raise ValueError(f"Erro ao conectar com a OpenAI: {e}")
    
    def _test_connection(self) -> None:
        """Testa conex√£o com a OpenAI API"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1,
                temperature=0
            )
        except Exception as e:
            raise ValueError(f"Falha no teste de conex√£o com OpenAI: {e}")
    
    def generate_response(
        self,
        user_message: str,
        context: Dict[str, Any],
        knowledge: Dict[str, Any],
        config: Dict[str, Any]
    ) -> str:
        """‚úÖ MELHORADO: Gera resposta consultiva com descoberta ativa"""
        
        # Constr√≥i prompt do sistema robusto
        system_prompt = self._build_consultive_system_prompt(knowledge, config, context)
        
        # Constr√≥i mensagens para o modelo
        messages = self._build_messages_with_memory(user_message, context, system_prompt)
        
        # Chama API
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )
        
        return response.choices[0].message.content
    
    def _build_consultive_system_prompt(
        self, 
        knowledge: Dict[str, Any],
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """‚úÖ NOVO: Prompt consultivo com descoberta ativa e mem√≥ria robusta"""
        
        agent_name = config.get("agent_name", "Timmy")
        business_name = config.get("business_name", "")
        personality = config.get("personality", {})
        memory_data = context.get("memory_data", {})
        analysis = context.get("analysis", {})
        
        # ‚úÖ NOVO: An√°lise do que ainda falta descobrir
        missing_info = self._analyze_missing_info(memory_data, context)
        discovery_priority = self._get_discovery_priority(missing_info, analysis)
        
        # ‚úÖ MELHORADO: Se√ß√£o de mem√≥ria ativa e robusta
        memory_section = ""
        if memory_data:
            client_name = memory_data.get("client_name")
            business_area = memory_data.get("business_area")
            mentioned_facts = memory_data.get("mentioned_facts", [])
            
            memory_section = f"""
üìã MEM√ìRIA COMPLETA DA CONVERSA:
- Nome do cliente: {client_name or "‚ùå N√ÉO INFORMADO - PERGUNTAR"}
- √Årea de neg√≥cio/empresa: {business_area or "‚ùå N√ÉO INFORMADO - PERGUNTAR"}
- Fatos importantes: {', '.join(mentioned_facts) if mentioned_facts else "‚ùå NENHUM - DESCOBRIR PROBLEMAS"}

üéØ REGRAS DE MEM√ìRIA:
- SEMPRE se refira ao cliente pelo nome quando souber
- SEMPRE relembre detalhes espec√≠ficos mencionados
- SE o cliente disser "esqueceu?" ou "j√° falei", revise a conversa completa
- NUNCA diga "n√£o mencionou" se a informa√ß√£o est√° no hist√≥rico
"""

        # ‚úÖ NOVO: Se√ß√£o de descoberta ativa
        discovery_section = f"""
üîç DESCOBERTA ATIVA (PRIORIDADE M√ÅXIMA):
{discovery_priority}

üìù PERGUNTAS DE DESCOBERTA OBRIGAT√ìRIAS:
1. Nome: "Qual seu nome?" ou "Como posso me dirigir a voc√™?"
2. Neg√≥cio: "Que tipo de neg√≥cio voc√™ tem?" ou "Em que √°rea voc√™ atua?"
3. Problemas: "Quais s√£o seus maiores desafios com atendimento?" 
4. Volume: "Quantos atendimentos voc√™s fazem por m√™s?"
5. Dores: "O que mais consome tempo da sua equipe?"

‚ö†Ô∏è S√ì APRESENTE PLANOS DEPOIS DE ENTENDER O CLIENTE!
"""

        # ‚úÖ NOVO: Se√ß√£o de pol√≠ticas (anti-alucina√ß√£o)
        policies_section = ""
        if "policies" in knowledge:
            policies = knowledge["policies"]
            policies_section = f"""
üö´ POL√çTICAS OBRIGAT√ìRIAS (NUNCA INVENTE):
- Pagamento: {policies.get('payment', {}).get('methods', ['Consultar comercial'])}
- Cancelamento: {policies.get('cancellation', {}).get('contract_type', 'Consultar suporte')}
- Suporte: {policies.get('support', {}).get('channels', ['Consultar comercial'])}

üîí REGRA CR√çTICA: Se n√£o souber informa√ß√£o espec√≠fica ‚Üí "Entre em contato com nosso comercial"
"""

        # ‚úÖ NOVO: Sauda√ß√£o personalizada
        greeting_section = ""
        if context.get("is_greeting", False):
            greeting_template = context.get("greeting_template", "")
            greeting_section = f"""
üëã PRIMEIRA INTERA√á√ÉO:
- Use sauda√ß√£o: "{greeting_template}"
- Seja caloroso e profissional
- IMEDIATAMENTE inicie descoberta: "Para te ajudar melhor, qual seu nome e que tipo de neg√≥cio voc√™ tem?"
"""

        # ‚úÖ NOVO: L√≥gica consultiva vs informativa
        approach_section = f"""
üéØ ABORDAGEM CONSULTIVA:
{self._get_consultive_approach(missing_info, analysis)}
"""

        prompt = f"""Voc√™ √© {agent_name}, consultor especialista em automa√ß√£o de atendimento da {business_name}.

PERSONALIDADE CONSULTIVA:
- Tom: {personality.get('tone', 'profissional e consultivo')}
- Estilo: {personality.get('style', 'descoberta ativa, entende primeiro')}
- Abordagem: SEMPRE consultiva - entenda PRIMEIRO, recomende DEPOIS

{memory_section}

{discovery_section}

{approach_section}

{policies_section}

{greeting_section}

CONHECIMENTO BASE:
{json.dumps(knowledge, indent=2, ensure_ascii=False)}

üéØ REGRAS DE RESPOSTA CONSULTIVA:
1. PRIORIDADE 1: Descobrir informa√ß√µes em falta (nome, neg√≥cio, problemas)
2. PRIORIDADE 2: Entender dores e necessidades espec√≠ficas  
3. PRIORIDADE 3: S√≥ ent√£o recomendar solu√ß√£o adequada
4. SEMPRE use informa√ß√µes APENAS do knowledge base
5. NUNCA invente pre√ßos, condi√ß√µes ou pol√≠ticas
6. Use formata√ß√£o WhatsApp nativa (*negrito*, n√£o **markdown**)
7. Seja consultivo: fa√ßa perguntas, escute, entenda, DEPOIS venda

CONTEXTO ATUAL:
- Fase da conversa: {analysis.get('conversation_phase', 'ongoing')}
- Intent detectado: {analysis.get('detected_intent', 'discovery_needed')}
- Informa√ß√µes em falta: {', '.join(missing_info) if missing_info else 'Nenhuma'}
"""
        
        # Adiciona instru√ß√µes espec√≠ficas do tenant
        if "system_instructions" in config:
            prompt += f"\n\nINSTRU√á√ïES ESPEC√çFICAS DO TENANT:\n{config['system_instructions']}"
        
        return prompt
    
    def _analyze_missing_info(self, memory_data: Dict[str, Any], context: Dict[str, Any]) -> List[str]:
        """‚úÖ NOVO: Analisa que informa√ß√µes ainda faltam descobrir"""
        missing = []
        
        if not memory_data.get("client_name"):
            missing.append("nome_cliente")
        
        if not memory_data.get("business_area"):
            missing.append("tipo_negocio")
        
        if not memory_data.get("mentioned_facts"):
            missing.append("problemas_atuais")
        
        # Verifica se j√° perguntou sobre volume de atendimento
        history = context.get("history", [])
        volume_mentioned = any("atendimento" in msg.get("content", "").lower() 
                             for msg in history if msg.get("role") == "user")
        if not volume_mentioned:
            missing.append("volume_atendimento")
        
        return missing
    
    def _get_discovery_priority(self, missing_info: List[str], analysis: Dict[str, Any]) -> str:
        """‚úÖ NOVO: Define prioridade de descoberta baseada no que falta"""
        if not missing_info:
            return "‚úÖ Informa√ß√µes b√°sicas coletadas. Focar em aprofundar necessidades."
        
        # Mapeamento de prioridades
        priority_map = {
            "nome_cliente": "üî• URGENTE: Pergunte o nome do cliente",
            "tipo_negocio": "üî• URGENTE: Descubra que tipo de neg√≥cio/empresa tem",
            "problemas_atuais": "‚ö° IMPORTANTE: Entenda os problemas atuais com atendimento",
            "volume_atendimento": "üìä RELEVANTE: Pergunte quantos atendimentos fazem por m√™s"
        }
        
        priorities = []
        for info in missing_info:
            if info in priority_map:
                priorities.append(priority_map[info])
        
        return "\n".join(priorities)
    
    def _get_consultive_approach(self, missing_info: List[str], analysis: Dict[str, Any]) -> str:
        """‚úÖ NOVO: Define abordagem baseada na fase da conversa"""
        
        if missing_info:
            return """
üìã FASE: DESCOBERTA ATIVA
- Fa√ßa perguntas diretas mas amig√°veis
- Mostre interesse genu√≠no no neg√≥cio do cliente  
- N√ÉO mencione planos at√© entender as necessidades
- Use descoberta para criar conex√£o
"""
        
        detected_intent = analysis.get("detected_intent", "general")
        
        if detected_intent == "pricing":
            return """
üí∞ FASE: CONSULTA DE PRE√áOS
- Cliente j√° quer saber pre√ßos
- Pode apresentar planos, MAS contextualizado √†s necessidades
- Destaque o plano mais adequado ao perfil descoberto
- Use descoberta pr√©via para personalizar recomenda√ß√£o
"""
        
        return """
üéØ FASE: CONSULTORIA
- Cliente informado, mas ainda descobrindo
- Aprofunde entendimento de dores espec√≠ficas
- Apresente valor antes de pre√ßo
- Seja educativo sobre automa√ß√£o de atendimento
"""
    
    def _build_messages_with_memory(
        self,
        user_message: str,
        context: Dict[str, Any],
        system_prompt: str
    ) -> List[Dict[str, str]]:
        """‚úÖ MELHORADO: Constr√≥i array com TODA a conversa para mem√≥ria ativa"""
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # ‚úÖ NOVO: Adiciona TODA a conversa (mem√≥ria completa)
        history = context.get("history", [])
        for msg in history:  # SEM LIMITE - toda a conversa
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # Adiciona mensagem atual
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        return messages